# NEURAL STYLE TRANSFER

COMPANY: CODTECH IT SOLUTIONS

NAME: GYAN PONNAPPA

INTERN ID: CT04DY2521

DOMAIN: AI

DURATION: 4 WEEKS

MENTOR: NEELA SANTOSH

<img width="1183" height="572" alt="Screenshot 2025-10-14 133448" src="https://github.com/user-attachments/assets/da87070d-add1-4f92-81b0-bb2253e6df91" />
<img width="1165" height="596" alt="Screenshot 2025-10-14 133550" src="https://github.com/user-attachments/assets/aa3a82ca-eeec-4be7-9d77-063ea4ed9872" />
<img width="1269" height="585" alt="Screenshot 2025-10-14 133524" src="https://github.com/user-attachments/assets/6b3a2894-5782-43a8-a0ce-ea2c4058556f" />
<img width="1186" height="579" alt="Screenshot 2025-10-14 133504" src="https://github.com/user-attachments/assets/ba651a7d-0323-476b-b4db-45f856183c42" />


Neural Style Transfer (for Photos)
ğŸ“˜ Overview

The Neural Style Transfer (NST) project is a fascinating application of Deep Learning that merges art and artificial intelligence. It allows a user to transform an ordinary photograph by applying the artistic style of another image (such as a famous painting) onto it. In essence, Neural Style Transfer combines the content of one image with the style of another, creating a visually stunning and artistically rich output.

This project demonstrates how Convolutional Neural Networks (CNNs) can understand and manipulate the high-level visual features of images â€” such as texture, patterns, and color distribution. The model extracts the â€œcontentâ€ from the target photo and the â€œstyleâ€ from the reference image, then optimizes a third image that fuses both characteristics. Itâ€™s one of the most visually engaging examples of deep learning applied to computer vision.

âš™ï¸ Key Features

ğŸ§  Style and Content Fusion: Combines the structural content of one image with the artistic patterns of another.

ğŸ¨ Custom Style Inputs: Users can choose any artwork or painting to transfer its style onto their own photos.

ğŸ”„ Multi-layer Feature Extraction: Uses multiple CNN layers to capture both low-level and high-level visual features.

âš™ï¸ Adjustable Style-Content Ratio: Users can control the balance between maintaining photo realism or enhancing artistic abstraction.

âš¡ GPU Acceleration Support: Supports CUDA-enabled GPUs for faster image generation.

ğŸ–¼ï¸ High-Resolution Outputs: Generates detailed, high-quality stylized images suitable for artistic and commercial purposes.

ğŸ§© Tools and Technologies

Programming Language: Python 3.x

Libraries and Frameworks:

ğŸ§® TensorFlow / PyTorch â€“ For building and training the neural style transfer model using convolutional neural networks.

ğŸ“· OpenCV â€“ For image input/output, resizing, and preprocessing.

ğŸ§  NumPy â€“ For handling multi-dimensional arrays and mathematical operations.

ğŸ¨ Matplotlib â€“ For visualizing intermediate outputs and results.

ğŸ–¼ï¸ PIL (Python Imaging Library) â€“ For easy image manipulation and saving.

âš™ï¸ scikit-image â€“ For additional image transformations and normalization.

ğŸ’» Applications

Digital Art Creation: Generate paintings and artistic imagery from ordinary photos.

Content Generation: Used by designers and artists to create unique visuals for marketing or social media.

Photo Editing Tools: Integrated into mobile and desktop apps like Prisma or DeepArt.

Film and Game Design: Apply specific art styles to concept images and backgrounds.

Cultural Preservation: Digitally reproduce and reinterpret classical art using modern photos.

AI-based Filters: Develop real-time artistic filters in AR/VR applications and photo editing software.

ğŸš€ How It Works

The algorithm takes two input images: a content image (the main photo) and a style image (the artwork).

Both images are passed through a pre-trained CNN (usually VGG19) to extract content and style features.

The content loss measures how much the generated image differs from the content image, while the style loss measures how much it differs from the style image.

An optimization algorithm (such as L-BFGS or Adam) iteratively updates the generated image to minimize the combined loss.

The output is a stylized photo blending the structure of the original image with the visual essence of the chosen artwork.

ğŸ”® Future Enhancements

Real-time video style transfer for dynamic scenes.

Style interpolation between multiple artworks.

Mobile and web app deployment for on-the-go photo stylization.

Incorporation of GANs (Generative Adversarial Networks) for more realistic and creative results.
